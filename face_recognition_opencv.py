"""
=============================================================================
ğŸ” ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ (OpenCV ì „ìš© - dlib ë¶ˆí•„ìš”!)
=============================================================================

íŠ¹ì§•:
- dlib, face_recognition ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆí•„ìš”!
- OpenCVë§Œ ì‚¬ìš© (ì„¤ì¹˜ ê°„í¸)
- ë§¥ë¶ M1/M3ì—ì„œ ì™„ë²½ í˜¸í™˜

ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬:
- opencv-python: ì–¼êµ´ ê²€ì¶œ ë° íŠ¹ì§• ì¶”ì¶œ
- numpy: ìˆ˜ì¹˜ ê³„ì‚°
- scikit-learn: ìœ ì‚¬ë„ ê³„ì‚° (ì„ íƒ)

ì„¤ì¹˜:
    pip3 install opencv-python numpy

ì‚¬ìš©ë²•:
    python3 face_recognition_opencv.py

=============================================================================
"""

import cv2
import numpy as np
import os
import pickle
from datetime import datetime

# =============================================================================
# ì„¤ì •
# =============================================================================

class Config:
    PHOTOS_TO_REGISTER = 30      # ë“±ë¡í•  ì‚¬ì§„ ìˆ˜ (30ì¥ìœ¼ë¡œ ì¦ê°€!)
    RECOGNITION_THRESHOLD = 0.6  # ì¸ì‹ ì„ê³„ê°’ (ë‚®ì„ìˆ˜ë¡ ì—„ê²©)
    CAMERA_WIDTH = 1280
    CAMERA_HEIGHT = 720
    FACE_SIZE = (160, 160)       # ì–¼êµ´ ì •ê·œí™” í¬ê¸°


# =============================================================================
# ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œê¸° (OpenCV ê¸°ë°˜)
# =============================================================================

class FaceFeatureExtractor:
    """
    OpenCVë¥¼ ì‚¬ìš©í•œ ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ
    
    ë°©ë²•:
    1. ì–¼êµ´ ê²€ì¶œ (Haar Cascade ë˜ëŠ” DNN)
    2. ì–¼êµ´ ì˜ì—­ ì •ê·œí™” (í¬ê¸°, ë°ê¸°)
    3. íŠ¹ì§• ë²¡í„° ì¶”ì¶œ (íˆìŠ¤í† ê·¸ë¨ + LBP + ORB)
    """
    
    def __init__(self):
        # ì–¼êµ´ ê²€ì¶œê¸° (Haar Cascade)
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        
        # DNN ì–¼êµ´ ê²€ì¶œê¸° (ë” ì •í™•í•¨) - ì„ íƒì  ì‚¬ìš©
        self.use_dnn = False
        try:
            # OpenCV DNN ì–¼êµ´ ê²€ì¶œ ëª¨ë¸ (Caffe)
            model_path = cv2.data.haarcascades.replace('haarcascades/', '')
            prototxt = os.path.join(model_path, 'deploy.prototxt')
            caffemodel = os.path.join(model_path, 'res10_300x300_ssd_iter_140000.caffemodel')
            
            if os.path.exists(prototxt) and os.path.exists(caffemodel):
                self.face_net = cv2.dnn.readNetFromCaffe(prototxt, caffemodel)
                self.use_dnn = True
        except:
            pass
        
        # ORB íŠ¹ì§•ì  ê²€ì¶œê¸°
        self.orb = cv2.ORB_create(nfeatures=500)
        
        # LBP íŒŒë¼ë¯¸í„°
        self.lbp_radius = 1
        self.lbp_neighbors = 8
        
        print(f"   ì–¼êµ´ ê²€ì¶œ: {'DNN' if self.use_dnn else 'Haar Cascade'}")
    
    def detect_faces(self, frame):
        """ì–¼êµ´ ê²€ì¶œ"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        faces = self.face_cascade.detectMultiScale(
            gray,
            scaleFactor=1.1,
            minNeighbors=5,
            minSize=(80, 80)
        )
        
        # (x, y, w, h) í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        return faces
    
    def extract_face(self, frame, face_rect):
        """ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ ë° ì •ê·œí™”"""
        x, y, w, h = face_rect
        
        # ì—¬ìœ  ê³µê°„ ì¶”ê°€ (ì–¼êµ´ ì£¼ë³€ í¬í•¨)
        margin = int(0.2 * w)
        x1 = max(0, x - margin)
        y1 = max(0, y - margin)
        x2 = min(frame.shape[1], x + w + margin)
        y2 = min(frame.shape[0], y + h + margin)
        
        face_img = frame[y1:y2, x1:x2]
        
        if face_img.size == 0:
            return None
        
        # í¬ê¸° ì •ê·œí™”
        face_img = cv2.resize(face_img, Config.FACE_SIZE)
        
        # ë°ê¸° ì •ê·œí™” (íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”)
        if len(face_img.shape) == 3:
            # ì»¬ëŸ¬ ì´ë¯¸ì§€
            lab = cv2.cvtColor(face_img, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            l = cv2.equalizeHist(l)
            lab = cv2.merge([l, a, b])
            face_img = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        
        return face_img
    
    def compute_lbp(self, gray_img):
        """Local Binary Pattern ê³„ì‚°"""
        h, w = gray_img.shape
        lbp = np.zeros_like(gray_img)
        
        for i in range(1, h-1):
            for j in range(1, w-1):
                center = gray_img[i, j]
                code = 0
                code |= (gray_img[i-1, j-1] >= center) << 7
                code |= (gray_img[i-1, j] >= center) << 6
                code |= (gray_img[i-1, j+1] >= center) << 5
                code |= (gray_img[i, j+1] >= center) << 4
                code |= (gray_img[i+1, j+1] >= center) << 3
                code |= (gray_img[i+1, j] >= center) << 2
                code |= (gray_img[i+1, j-1] >= center) << 1
                code |= (gray_img[i, j-1] >= center) << 0
                lbp[i, j] = code
        
        return lbp
    
    def extract_features(self, face_img):
        """
        ì–¼êµ´ì—ì„œ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ
        
        ì¡°í•©:
        1. ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨ (ì „ì²´ì ì¸ ìƒ‰ ë¶„í¬)
        2. LBP íˆìŠ¤í† ê·¸ë¨ (í…ìŠ¤ì²˜ íŒ¨í„´)
        3. HOG íŠ¹ì§• (í˜•íƒœ)
        """
        if face_img is None:
            return None
        
        features = []
        
        gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)
        
        # 1. ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨ (HSV)
        hsv = cv2.cvtColor(face_img, cv2.COLOR_BGR2HSV)
        
        # H ì±„ë„ íˆìŠ¤í† ê·¸ë¨
        h_hist = cv2.calcHist([hsv], [0], None, [32], [0, 180])
        h_hist = cv2.normalize(h_hist, h_hist).flatten()
        features.extend(h_hist)
        
        # S ì±„ë„ íˆìŠ¤í† ê·¸ë¨
        s_hist = cv2.calcHist([hsv], [1], None, [32], [0, 256])
        s_hist = cv2.normalize(s_hist, s_hist).flatten()
        features.extend(s_hist)
        
        # 2. LBP íˆìŠ¤í† ê·¸ë¨ (í…ìŠ¤ì²˜)
        lbp = self.compute_lbp(gray)
        lbp_hist = cv2.calcHist([lbp], [0], None, [64], [0, 256])
        lbp_hist = cv2.normalize(lbp_hist, lbp_hist).flatten()
        features.extend(lbp_hist)
        
        # 3. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ íˆìŠ¤í† ê·¸ë¨
        gray_hist = cv2.calcHist([gray], [0], None, [32], [0, 256])
        gray_hist = cv2.normalize(gray_hist, gray_hist).flatten()
        features.extend(gray_hist)
        
        # 4. ì–¼êµ´ ì˜ì—­ë³„ ë°ê¸° í‰ê·  (ê°„ë‹¨í•œ ê³µê°„ ì •ë³´)
        h, w = gray.shape
        grid_size = 4
        cell_h, cell_w = h // grid_size, w // grid_size
        
        for i in range(grid_size):
            for j in range(grid_size):
                cell = gray[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w]
                features.append(np.mean(cell) / 255.0)
                features.append(np.std(cell) / 255.0)
        
        return np.array(features, dtype=np.float32)
    
    def compute_similarity(self, features1, features2):
        """ë‘ íŠ¹ì§• ë²¡í„°ì˜ ìœ ì‚¬ë„ ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)"""
        if features1 is None or features2 is None:
            return 0.0
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        dot_product = np.dot(features1, features2)
        norm1 = np.linalg.norm(features1)
        norm2 = np.linalg.norm(features2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        similarity = dot_product / (norm1 * norm2)
        
        return similarity


# =============================================================================
# ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ
# =============================================================================

class FaceRecognitionSystem:
    """
    OpenCV ê¸°ë°˜ ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ
    """
    
    def __init__(self):
        print("=" * 55)
        print("ğŸ” ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (OpenCV ì „ìš©)")
        print("=" * 55)
        
        # íŠ¹ì§• ì¶”ì¶œê¸°
        self.extractor = FaceFeatureExtractor()
        
        # ë“±ë¡ëœ ë°ì´í„°
        self.registered_name = None
        self.registered_features = []     # ë“±ë¡ëœ íŠ¹ì§•ë“¤
        self.registered_feature_avg = None  # í‰ê·  íŠ¹ì§•
        
        # ì €ì¥ í´ë”
        self.save_folder = "face_data"
        os.makedirs(self.save_folder, exist_ok=True)
        
        print("âœ… ì´ˆê¸°í™” ì™„ë£Œ!\n")
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰"""
        print("=" * 55)
        print("ğŸš€ í”„ë¡œê·¸ë¨ ì‹œì‘")
        print("=" * 55)
        
        # ì €ì¥ëœ ë°ì´í„° í™•ì¸
        if self._load_data():
            print(f"\nâœ… ì €ì¥ëœ ë°ì´í„° ë°œê²¬: {self.registered_name}")
            response = input("   ì´ ë°ì´í„°ë¥¼ ì‚¬ìš©í• ê¹Œìš”? [y/n]: ").strip().lower()
            if response == 'y' or response == '':
                self._recognition_mode()
                return
        
        # ë“±ë¡ ëª¨ë“œ ì‹œì‘
        self._registration_mode()
    
    # =========================================================================
    # ë“±ë¡ ëª¨ë“œ
    # =========================================================================
    
    def _registration_mode(self):
        """ì–¼êµ´ ë“±ë¡"""
        print("\n" + "=" * 55)
        print("ğŸ“ ì–¼êµ´ ë“±ë¡ ëª¨ë“œ")
        print("=" * 55)
        
        name = input("\në“±ë¡í•  ì‚¬ëŒ ì´ë¦„: ").strip()
        if not name:
            name = "User"
        self.registered_name = name
        
        print(f"\n'{name}'ë‹˜ì˜ ì–¼êµ´ì„ {Config.PHOTOS_TO_REGISTER}ì¥ ì´¬ì˜í•©ë‹ˆë‹¤.")
        print("30ì¥ì„ ì´¬ì˜í•˜ë©´ ì¸ì‹ ì •í™•ë„ê°€ í›¨ì”¬ ë†’ì•„ì ¸ìš”!")
        print("ë‹¤ì–‘í•œ ê°ë„, í‘œì •, ì¡°ëª…ìœ¼ë¡œ ì´¬ì˜í•´ì£¼ì„¸ìš”!\n")
        print("ğŸ“‹ ì¡°ì‘:")
        print("   SPACE: ì´¬ì˜")
        print("   A: ìë™ ì´¬ì˜")
        print("   Q: ì™„ë£Œ")
        print("   ESC: ì¢…ë£Œ\n")
        
        camera = cv2.VideoCapture(0)
        if not camera.isOpened():
            print("âŒ ì¹´ë©”ë¼ ì—´ê¸° ì‹¤íŒ¨!")
            return
        
        camera.set(cv2.CAP_PROP_FRAME_WIDTH, Config.CAMERA_WIDTH)
        camera.set(cv2.CAP_PROP_FRAME_HEIGHT, Config.CAMERA_HEIGHT)
        
        self.registered_features = []
        photo_count = 0
        auto_mode = False
        last_time = 0
        
        guides = [
            "1. ì •ë©´", "2. ì™¼ìª½ 15Â°", "3. ì™¼ìª½ 30Â°", "4. ì™¼ìª½ 45Â°",
            "5. ì˜¤ë¥¸ìª½ 15Â°", "6. ì˜¤ë¥¸ìª½ 30Â°", "7. ì˜¤ë¥¸ìª½ 45Â°",
            "8. ìœ„ 15Â°", "9. ìœ„ 30Â°", "10. ì•„ë˜ 15Â°", "11. ì•„ë˜ 30Â°",
            "12. ì™¼ìª½+ìœ„", "13. ì™¼ìª½+ì•„ë˜", "14. ì˜¤ë¥¸ìª½+ìœ„", "15. ì˜¤ë¥¸ìª½+ì•„ë˜",
            "16. ì›ƒëŠ” ì–¼êµ´", "17. ë¬´í‘œì •", "18. ëˆˆ í¬ê²Œ", "19. ì… ë²Œë¦¬ê¸°",
            "20. ì°¡ê·¸ë¦¬ê¸°", "21. ë†€ë€ í‘œì •", "22. ì •ë©´(ì¡°ëª… ì™¼ìª½)",
            "23. ì •ë©´(ì¡°ëª… ì˜¤ë¥¸ìª½)", "24. ì•ˆê²½ ì“°ê³ (ìˆë‹¤ë©´)",
            "25. ë¨¸ë¦¬ ë„˜ê¸°ê¸°", "26-30. ììœ ë¡­ê²Œ"
        ]
        
        print("ğŸ“· ì¹´ë©”ë¼ ì¤€ë¹„ë¨!\n")
        
        while photo_count < Config.PHOTOS_TO_REGISTER:
            ret, frame = camera.read()
            if not ret:
                break
            
            frame = cv2.flip(frame, 1)
            display = frame.copy()
            h, w = display.shape[:2]
            
            # ì–¼êµ´ ê²€ì¶œ
            faces = self.extractor.detect_faces(frame)
            face_ok = len(faces) == 1
            
            # ì–¼êµ´ í‘œì‹œ
            for (x, y, fw, fh) in faces:
                color = (0, 255, 0) if face_ok else (0, 165, 255)
                cv2.rectangle(display, (x, y), (x+fw, y+fh), color, 2)
            
            # ì •ë³´ í‘œì‹œ
            cv2.putText(display, f"Registration: {name}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            cv2.putText(display, f"Photos: {photo_count}/{Config.PHOTOS_TO_REGISTER}", 
                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            
            status = "Face OK" if face_ok else ("Multiple faces!" if len(faces) > 1 else "No face")
            color = (0, 255, 0) if face_ok else (0, 0, 255)
            cv2.putText(display, status, (10, 90),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
            
            mode_text = "AUTO (1sec)" if auto_mode else "MANUAL (SPACE)"
            cv2.putText(display, mode_text, (10, 120),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            
            # í¬ì¦ˆ ê°€ì´ë“œ
            if photo_count < len(guides):
                cv2.putText(display, f"Pose: {guides[photo_count]}", (10, h-20),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
            
            # ìë™ ì´¬ì˜
            current_time = cv2.getTickCount() / cv2.getTickFrequency()
            if auto_mode and face_ok and (current_time - last_time) >= 1.0:
                self._capture_face(frame, faces[0])
                photo_count += 1
                last_time = current_time
                print(f"ğŸ“¸ ìë™ ì´¬ì˜ {photo_count}/{Config.PHOTOS_TO_REGISTER}")
            
            cv2.imshow("Face Registration", display)
            
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord(' ') and face_ok and not auto_mode:
                self._capture_face(frame, faces[0])
                photo_count += 1
                print(f"ğŸ“¸ ì´¬ì˜ {photo_count}/{Config.PHOTOS_TO_REGISTER}")
            
            elif key == ord('a'):
                auto_mode = not auto_mode
                last_time = current_time
                print(f"ğŸ”„ ìë™ ëª¨ë“œ: {'ON' if auto_mode else 'OFF'}")
            
            elif key == ord('q') and photo_count >= 5:
                break
            
            elif key == 27:
                camera.release()
                cv2.destroyAllWindows()
                return
        
        camera.release()
        cv2.destroyAllWindows()
        
        if len(self.registered_features) >= 5:
            # í‰ê·  íŠ¹ì§• ê³„ì‚°
            self.registered_feature_avg = np.mean(self.registered_features, axis=0)
            print(f"\nâœ… '{name}' ë“±ë¡ ì™„ë£Œ! ({len(self.registered_features)}ì¥)")
            
            self._save_data()
            
            input("\nEnterë¥¼ ëˆŒëŸ¬ ì¸ì‹ ëª¨ë“œë¡œ...")
            self._recognition_mode()
    
    def _capture_face(self, frame, face_rect):
        """ì–¼êµ´ ìº¡ì²˜ ë° íŠ¹ì§• ì¶”ì¶œ"""
        face_img = self.extractor.extract_face(frame, face_rect)
        if face_img is not None:
            features = self.extractor.extract_features(face_img)
            if features is not None:
                self.registered_features.append(features)
    
    # =========================================================================
    # ì¸ì‹ ëª¨ë“œ
    # =========================================================================
    
    def _recognition_mode(self):
        """ì‹¤ì‹œê°„ ì–¼êµ´ ì¸ì‹"""
        print("\n" + "=" * 55)
        print("ğŸ‘ï¸ ì–¼êµ´ ì¸ì‹ ëª¨ë“œ")
        print("=" * 55)
        print(f"\në“±ë¡ëœ ì‚¬ëŒ: {self.registered_name}")
        print(f"ì„ê³„ê°’: {Config.RECOGNITION_THRESHOLD}")
        print("\nğŸ“‹ ì¡°ì‘:")
        print("   R: ë‹¤ì‹œ ë“±ë¡")
        print("   +/-: ì„ê³„ê°’ ì¡°ì ˆ")
        print("   S: ì €ì¥")
        print("   ESC: ì¢…ë£Œ\n")
        
        camera = cv2.VideoCapture(0)
        if not camera.isOpened():
            print("âŒ ì¹´ë©”ë¼ ì—´ê¸° ì‹¤íŒ¨!")
            return
        
        camera.set(cv2.CAP_PROP_FRAME_WIDTH, Config.CAMERA_WIDTH)
        camera.set(cv2.CAP_PROP_FRAME_HEIGHT, Config.CAMERA_HEIGHT)
        
        print("ğŸ“· ì‹¤ì‹œê°„ ì¸ì‹ ì‹œì‘!\n")
        
        frame_count = 0
        start_time = cv2.getTickCount() / cv2.getTickFrequency()
        
        threshold = Config.RECOGNITION_THRESHOLD
        
        while True:
            ret, frame = camera.read()
            if not ret:
                break
            
            frame = cv2.flip(frame, 1)
            display = frame.copy()
            h, w = display.shape[:2]
            
            # ì–¼êµ´ ê²€ì¶œ
            faces = self.extractor.detect_faces(frame)
            
            # ê° ì–¼êµ´ ì¸ì‹
            for (x, y, fw, fh) in faces:
                # íŠ¹ì§• ì¶”ì¶œ
                face_img = self.extractor.extract_face(frame, (x, y, fw, fh))
                features = self.extractor.extract_features(face_img)
                
                if features is not None:
                    # ìœ ì‚¬ë„ ê³„ì‚°
                    similarity = self.extractor.compute_similarity(
                        features, self.registered_feature_avg
                    )
                    
                    # íŒì •
                    is_match = similarity >= threshold
                    
                    if is_match:
                        color = (0, 255, 0)
                        confidence = similarity * 100
                        label = f"{self.registered_name} ({confidence:.0f}%)"
                    else:
                        color = (0, 0, 255)
                        label = "Unknown"
                    
                    # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                    cv2.rectangle(display, (x, y), (x+fw, y+fh), color, 2)
                    
                    # ë¼ë²¨ ë°°ê²½
                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
                    cv2.rectangle(display, (x, y-30), (x+label_size[0]+10, y), color, -1)
                    
                    # ë¼ë²¨ í…ìŠ¤íŠ¸
                    cv2.putText(display, label, (x+5, y-8),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    
                    # ìœ ì‚¬ë„ í‘œì‹œ
                    cv2.putText(display, f"Sim: {similarity:.2f}", (x, y+fh+20),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
            
            # FPS
            frame_count += 1
            elapsed = (cv2.getTickCount() / cv2.getTickFrequency()) - start_time
            fps = frame_count / elapsed if elapsed > 0 else 0
            
            # ìƒíƒœ í‘œì‹œ
            cv2.putText(display, f"Recognition Mode | FPS: {fps:.1f}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(display, f"Registered: {self.registered_name}", (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(display, f"Threshold: {threshold:.2f} (+/-)", (10, 90),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            
            # ë²”ë¡€
            cv2.rectangle(display, (w-180, 10), (w-10, 70), (50, 50, 50), -1)
            cv2.putText(display, "GREEN=Match", (w-170, 35),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
            cv2.putText(display, "RED=Unknown", (w-170, 55),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
            
            cv2.imshow("Face Recognition", display)
            
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('r'):
                camera.release()
                cv2.destroyAllWindows()
                self._registration_mode()
                return
            
            elif key == ord('+') or key == ord('='):
                threshold = min(0.95, threshold + 0.05)
                print(f"ì„ê³„ê°’: {threshold:.2f}")
            
            elif key == ord('-'):
                threshold = max(0.3, threshold - 0.05)
                print(f"ì„ê³„ê°’: {threshold:.2f}")
            
            elif key == ord('s'):
                self._save_data()
            
            elif key == 27:
                break
        
        camera.release()
        cv2.destroyAllWindows()
        print("\nğŸ‘‹ ì¢…ë£Œ")
    
    # =========================================================================
    # ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°
    # =========================================================================
    
    def _save_data(self):
        """ë°ì´í„° ì €ì¥"""
        filepath = os.path.join(self.save_folder, "face_opencv.pkl")
        
        data = {
            'name': self.registered_name,
            'features': self.registered_features,
            'feature_avg': self.registered_feature_avg
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(data, f)
        
        print(f"ğŸ’¾ ì €ì¥ë¨: {filepath}")
    
    def _load_data(self):
        """ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"""
        filepath = os.path.join(self.save_folder, "face_opencv.pkl")
        
        if os.path.exists(filepath):
            try:
                with open(filepath, 'rb') as f:
                    data = pickle.load(f)
                
                self.registered_name = data['name']
                self.registered_features = data['features']
                self.registered_feature_avg = data['feature_avg']
                return True
            except:
                pass
        return False


# =============================================================================
# ì‹¤í–‰
# =============================================================================

if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                           â•‘
    â•‘       ğŸ” ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ (OpenCV ì „ìš© ë²„ì „)              â•‘
    â•‘                                                           â•‘
    â•‘   âœ… dlib ë¶ˆí•„ìš”! opencv-pythonë§Œ ìˆìœ¼ë©´ OK               â•‘
    â•‘   âœ… ë§¥ë¶ M1/M3 ì™„ë²½ í˜¸í™˜                                 â•‘
    â•‘                                                           â•‘
    â•‘   ì„¤ì¹˜: pip3 install opencv-python numpy                  â•‘
    â•‘                                                           â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    system = FaceRecognitionSystem()
    system.run()